{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**第零部分 导入库**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, Dataset, DataLoader\n",
    "from torchvision import datasets\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from PIL import Image\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**第一部分 数据处理**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_DIR = 'data/VOC2012/JPEGImages'\n",
    "ANNOTATIONS_DIR = 'data/VOC2012/Annotations'\n",
    "LABEL_DIR = 'data/VOC2012/Labels'\n",
    "\n",
    "ANNOTATIONS = [f.split('.')[0] for f in os.listdir(ANNOTATIONS_DIR)]\n",
    "# ANNOTATIONS # 测试一下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "def convert(size, box):\n",
    "    dw = 1.0 / size[0]\n",
    "    dh = 1.0 / size[1]\n",
    "    x = (box[0] + box[1]) / 2.0 - 1\n",
    "    y = (box[2] + box[3]) / 2.0 - 1\n",
    "    w = box[1] - box[0]\n",
    "    h = box[3] - box[2]\n",
    "    x *= dw\n",
    "    w *= dw\n",
    "    y *= dh\n",
    "    h *= dh \n",
    "    return (x, y, w, h)\n",
    "\n",
    "def convert_labels(annotations_path, label_path, annotations):\n",
    "    classes = []\n",
    "    for a in annotations:\n",
    "        in_file = open(annotations_path + '/' + a + '.xml')\n",
    "        out_file = open(label_path + '/' + a + '.txt', 'w')\n",
    "\n",
    "        tree = ET.parse(in_file)\n",
    "        root = tree.getroot()\n",
    "        size = root.find('size')\n",
    "        w = int(size.find('width').text)\n",
    "        h = int(size.find('height').text)\n",
    "        \n",
    "        for obj in root.iter('object'):\n",
    "            cls = obj.find('name').text\n",
    "\n",
    "            if cls not in classes:\n",
    "                classes.append(cls)\n",
    "\n",
    "            cls_idx = classes.index(cls)\n",
    "            box = obj.find('bndbox')\n",
    "            b = (float(box.find('xmin').text),\n",
    "                 float(box.find('xmax').text),\n",
    "                 float(box.find('ymin').text),\n",
    "                 float(box.find('ymax').text))\n",
    "            \n",
    "            bbox = convert((w, h), b)\n",
    "            out_file.write(str(cls_idx) + \" \" + \n",
    "                           \" \".join([str(bb) for bb in bbox]) + '\\n')\n",
    "\n",
    "        in_file.close()\n",
    "        out_file.close()\n",
    "    return classes\n",
    "\n",
    "CLASS_INDICES = convert_labels(ANNOTATIONS_DIR, LABEL_DIR, ANNOTATIONS)\n",
    "CLASS_INDICES # 查看具体的类别"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**第二部分 Yolov3模型构建**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = [\n",
    "    ('B', 32, 3, 1),\n",
    "    ('B', 64, 3, 2),\n",
    "    ('R', 1),\n",
    "    ('B', 128, 3, 2),\n",
    "    ('R', 2),\n",
    "    ('B', 256, 3, 2),\n",
    "    ('R', 8),\n",
    "    ('B', 512, 3, 2),\n",
    "    ('R', 8),\n",
    "    ('B', 1024, 3, 2),\n",
    "    ('R', 4),\n",
    "    ('B', 512, 1, 1),\n",
    "    ('B', 1024, 3, 1),\n",
    "    ('P'),\n",
    "    ('B', 256, 1, 1),\n",
    "    ('U'),\n",
    "    ('B', 256, 1, 1),\n",
    "    ('B', 512, 3, 1),\n",
    "    ('P'),\n",
    "    ('B', 128, 1, 1),\n",
    "    ('U'),\n",
    "    ('B', 128, 1, 1),\n",
    "    ('B', 256, 3, 1),\n",
    "    ('P'),\n",
    "]\n",
    "\n",
    "class CNNBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, batch=True, act=True, **kwargs):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "\n",
    "        layers.append(nn.Conv2d(in_channels, out_channels, bias=not batch, **kwargs))\n",
    "\n",
    "        if batch:\n",
    "            layers.append(nn.BatchNorm2d(out_channels))\n",
    "        if act:\n",
    "            layers.append(nn.LeakyReLU(0.1, inplace=True))\n",
    "\n",
    "        self.block = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "    \n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, channels, num_blocks, res=True):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.num_blocks = num_blocks\n",
    "\n",
    "        for _ in range(num_blocks):\n",
    "            self.layers.append(\n",
    "                nn.Sequential(\n",
    "                    CNNBlock(channels, torch.div(channels, 2, rounding_mode='floor'), kernel_size=1),\n",
    "                    CNNBlock(torch.div(channels, 2, rounding_mode='floor'), channels, kernel_size=3, padding=1)\n",
    "                )\n",
    "            )\n",
    "        self.res = res\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            if self.res:\n",
    "                x = x + layer(x)\n",
    "            else:\n",
    "                x = layer(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "class Predict(nn.Module):\n",
    "    def __init__(self, in_channels, classes):\n",
    "        super().__init__()\n",
    "\n",
    "        self.layer = nn.Sequential(\n",
    "            CNNBlock(in_channels, 2*in_channels, kernel_size=3, padding=1),\n",
    "            CNNBlock(2*in_channels, (classes+5)*3,  batch=False, act=False, kernel_size=1),\n",
    "        )\n",
    "        self.classes = classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer(x)\n",
    "        x = x.reshape(x.shape[0], 3, self.classes+5, x.shape[2], x.shape[3])\n",
    "        x = x.permute(0, 1, 3, 4, 2)\n",
    "        return x\n",
    "    \n",
    "\n",
    "class YOLOv3(nn.Module):\n",
    "    def __init__(self, in_channels, classes):\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.classes = classes\n",
    "\n",
    "        self.layers = self._create_model()\n",
    "\n",
    "    def forward(self, x):\n",
    "        outs = []\n",
    "        route_conn = []\n",
    "\n",
    "        for layer in self.layers:\n",
    "            if isinstance(layer, Predict):\n",
    "                outs.append(layer(x))\n",
    "                continue\n",
    "            x = layer(x)\n",
    "\n",
    "            if isinstance(layer, ResidualBlock) and layer.num_blocks == 8:\n",
    "                route_conn.append(x)\n",
    "            elif isinstance(layer, nn.Upsample):\n",
    "                x = torch.cat([x, route_conn.pop()], dim=1)\n",
    "\n",
    "        return outs\n",
    "\n",
    "    def _create_model(self):\n",
    "        layers = nn.ModuleList()\n",
    "        in_channels = self.in_channels\n",
    "        \n",
    "        for element in config:\n",
    "            if element[0] == 'B':\n",
    "                _, out_channels, kernel_size, stride = element\n",
    "                padding = 0\n",
    "                if kernel_size == 3:\n",
    "                    padding = 1\n",
    "                layers.append(\n",
    "                    CNNBlock(\n",
    "                        in_channels,\n",
    "                        out_channels,\n",
    "                        kernel_size=kernel_size,\n",
    "                        stride=stride,\n",
    "                        padding=padding\n",
    "                    )\n",
    "                )\n",
    "                in_channels = out_channels\n",
    "\n",
    "            if element[0] == 'R':\n",
    "                _, blocks = element\n",
    "                layers.append(ResidualBlock(in_channels, blocks))\n",
    "\n",
    "            if element[0] == 'U':\n",
    "                layers.append(nn.Upsample(scale_factor=2),)\n",
    "                in_channels = in_channels * 3\n",
    "            \n",
    "            if element[0] == 'P':\n",
    "                layers += [\n",
    "                    ResidualBlock(in_channels, 1, res=False),\n",
    "                    CNNBlock(in_channels, torch.div(in_channels, 2, rounding_mode='floor'), kernel_size=1),\n",
    "                    Predict(torch.div(in_channels, 2, rounding_mode='floor'), self.classes)\n",
    "                ]\n",
    "                in_channels = torch.div(in_channels, 2, rounding_mode='floor')\n",
    "        return layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试模型结构和参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "yolo = YOLOv3(3, 20).to(device)\n",
    "# summary(yolo, (3, 416, 416))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**第三部分 utils函数**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置默认参数（训练时可更改）\n",
    "BATCH_SIZE = 32\n",
    "IMAGE_SIZE = 416\n",
    "NUM_CLASSES = 20\n",
    "LEARNING_RATE = 1e-5\n",
    "WEIGHT_DECAY = 1e-4\n",
    "NUM_EPOCHS = 100\n",
    "CONF_THRESHOLD = 0.05\n",
    "MAP_IOU_THRESH = 0.5\n",
    "NMS_IOU_THRESH = 0.45\n",
    "S = [IMAGE_SIZE // 32, IMAGE_SIZE // 16, IMAGE_SIZE // 8]\n",
    "\n",
    "ANCHORS = [\n",
    "    [(0.28, 0.22), (0.38, 0.48), (0.9, 0.78)],\n",
    "    [(0.07, 0.15), (0.15, 0.11), (0.14, 0.29)],\n",
    "    [(0.02, 0.03), (0.04, 0.07), (0.08, 0.06)],\n",
    "]\n",
    "\n",
    "# TO DO: Implement transforms\n",
    "train_transforms = A.Compose(\n",
    "    [\n",
    "        A.LongestMaxSize(max_size=int(IMAGE_SIZE * 1.1)),\n",
    "        A.PadIfNeeded(\n",
    "            min_height=int(IMAGE_SIZE * 1.1),\n",
    "            min_width=int(IMAGE_SIZE * 1.1),\n",
    "            border_mode=cv2.BORDER_CONSTANT,\n",
    "        ),\n",
    "        A.RandomCrop(width=IMAGE_SIZE, height=IMAGE_SIZE),\n",
    "        A.ColorJitter(brightness=0.6, contrast=0.6, \n",
    "                    saturation=0.6, hue=0.6, p=0.4),\n",
    "        A.ShiftScaleRotate(\n",
    "            rotate_limit=20, p=0.5, border_mode=cv2.BORDER_CONSTANT\n",
    "        )\n",
    "        ,\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.Blur(p=0.1),\n",
    "        A.CLAHE(p=0.1),\n",
    "        A.Posterize(p=0.1),\n",
    "        A.ToGray(p=0.1),\n",
    "        A.ChannelShuffle(p=0.05),\n",
    "        A.Normalize(mean=[0, 0, 0], std=[1, 1, 1], max_pixel_value=255,),\n",
    "        ToTensorV2(),\n",
    "    ],\n",
    "    bbox_params=A.BboxParams(format='yolo',\n",
    "                             min_visibility=0.4, \n",
    "                             label_fields=[]),\n",
    ")\n",
    "\n",
    "test_transforms = A.Compose(\n",
    "    [\n",
    "        A.LongestMaxSize(max_size=int(IMAGE_SIZE)), \n",
    "        A.PadIfNeeded(\n",
    "            min_height=int(IMAGE_SIZE),\n",
    "            min_width=int(IMAGE_SIZE),\n",
    "            border_mode=cv2.BORDER_CONSTANT,\n",
    "        ),  \n",
    "        A.Normalize(mean=[0, 0, 0], std=[1, 1, 1], max_pixel_value=255,),\n",
    "        ToTensorV2(),           \n",
    "    ],\n",
    "    bbox_params=A.BboxParams(format='yolo',\n",
    "                             min_visibility=0.4, \n",
    "                             label_fields=[]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou(box1, box2):\n",
    "    \"\"\"\n",
    "    Returns interection over union (using w and h)\n",
    "    \"\"\"\n",
    "\n",
    "    intersection = (torch.min(box1[..., 0], box2[..., 0]) *\n",
    "                  torch.min(box1[..., 1], box2[..., 1]))\n",
    "\n",
    "    union = (box1[..., 0] * box1[..., 1] +\n",
    "            box2[..., 0] * box2[..., 1] -\n",
    "            intersection)\n",
    "\n",
    "    return intersection / (union + 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection_over_union(box_pred, box_true, ciou=False):\n",
    "    \"\"\"\n",
    "    Returns intersection over union for real bboxes.\n",
    "    \"\"\"\n",
    "\n",
    "    box1_x1 = box_pred[..., 0:1] - box_pred[..., 2:3] / 2\n",
    "    box1_y1 = box_pred[..., 1:2] - box_pred[..., 3:4] / 2\n",
    "    box1_x2 = box_pred[..., 0:1] + box_pred[..., 2:3] / 2\n",
    "    box1_y2 = box_pred[..., 1:2] + box_pred[..., 3:4] / 2\n",
    "    box2_x1 = box_true[..., 0:1] - box_true[..., 2:3] / 2\n",
    "    box2_y1 = box_true[..., 1:2] - box_true[..., 3:4] / 2\n",
    "    box2_x2 = box_true[..., 0:1] + box_true[..., 2:3] / 2\n",
    "    box2_y2 = box_true[..., 1:2] + box_true[..., 3:4] / 2\n",
    "\n",
    "    x1 = torch.max(box1_x1, box2_x1)\n",
    "    y1 = torch.max(box1_y1, box2_y1)\n",
    "    x2 = torch.min(box1_x2, box2_x2)\n",
    "    y2 = torch.min(box1_y2, box2_y2)\n",
    "\n",
    "    intersection = (x2 - x1).clamp(0) * (y2 - y1).clamp(0)\n",
    "    box1_area = abs((box1_x2 - box1_x1) * (box1_y2 - box1_y1))\n",
    "    box2_area = abs((box2_x2 - box2_x1) * (box2_y2 - box2_y1))\n",
    "\n",
    "    return intersection / (box1_area + box2_area - intersection + 1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, optimizer, epoch, loss, project_name):\n",
    "    dir = \"trained_models/\" + project_name\n",
    "    if not os.path.exists(dir):\n",
    "        os.makedirs(dir)\n",
    "\n",
    "    path = dir + '/model.pth'\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': loss,\n",
    "    }, path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**第四部分 Dataset Loader**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, annotations, image_dir, label_dir, anchors, image_size=416,\n",
    "                 S=[13, 26, 52], C=20, transforms=None):\n",
    "        self.annotations = annotations\n",
    "        self.image_dir = image_dir\n",
    "        self.label_dir = label_dir\n",
    "        self.image_size = image_size\n",
    "        self.transforms = transforms\n",
    "        self.S = S\n",
    "        self.anchors = torch.tensor(anchors[0] + anchors[1] + anchors[2])\n",
    "        self.num_anchors = self.anchors.shape[0]\n",
    "        self.num_anchors_per_scale = torch.div(self.num_anchors, 3, rounding_mode='floor')\n",
    "        self.C = C\n",
    "        self.ignore_iou_thresh = 0.5\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        label_path = os.path.join(self.label_dir, self.annotations[index] + '.txt')\n",
    "        bboxes = np.roll(np.loadtxt(fname=label_path, delimiter=' ', ndmin=2),\n",
    "                         4, axis=1).tolist()\n",
    "        img_path = os.path.join(self.image_dir, self.annotations[index] + '.jpg')\n",
    "        image = np.array(Image.open(img_path).convert('RGB'))\n",
    "\n",
    "        if self.transforms:\n",
    "            augments = self.transforms(image=image, bboxes=bboxes)\n",
    "            image = augments['image']\n",
    "            bboxes = augments['bboxes']\n",
    "\n",
    "        targets = [torch.zeros((torch.div(self.num_anchors, 3, rounding_mode='floor'), S, S, 6)) for S in self.S]\n",
    "\n",
    "        for box in bboxes:\n",
    "            iou_anchors = iou(torch.tensor(box[2:4]), self.anchors)\n",
    "            anchor_indices = iou_anchors.argsort(descending=True, dim=0)\n",
    "            x, y, w, h, c = box\n",
    "            has_anchor = [False] * 3\n",
    "\n",
    "            for anchor_idx in anchor_indices:\n",
    "                scale_idx = torch.div(anchor_idx, self.num_anchors_per_scale, rounding_mode='floor')\n",
    "                anchor_on_scale = anchor_idx % self.num_anchors_per_scale\n",
    "                S = self.S[scale_idx]\n",
    "                i, j = int(S * y), int(S * x)\n",
    "                anchor_taken = targets[scale_idx][anchor_on_scale, i, j, 0]\n",
    "                if not anchor_taken and not has_anchor[scale_idx]:\n",
    "                    targets[scale_idx][anchor_on_scale, i, j, 0] = 1\n",
    "                    x_c, y_c = S * x - j, S * y - i\n",
    "                    w_c, h_c = (w * S, h * S)\n",
    "                    box_coordinates = torch.tensor([x_c, y_c, w_c, h_c])\n",
    "                    targets[scale_idx][anchor_on_scale, i, j, 1:5] = box_coordinates\n",
    "                    targets[scale_idx][anchor_on_scale, i, j, 5] = int(c)\n",
    "                    has_anchor[scale_idx] = True\n",
    "                elif not anchor_taken and iou_anchors[anchor_idx] > self.ignore_iou_thresh:\n",
    "                    targets[scale_idx][anchor_on_scale, i, j, 0] = -1\n",
    "\n",
    "        return image, tuple(targets)\n",
    "# TO DO: Test dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**第五部分 训练及测试函数**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(true, pred, device):\n",
    "    \"\"\"\n",
    "    Returns: class accuracy, object accuracy, no object accuracy\n",
    "    \"\"\"\n",
    "\n",
    "    total_c, correct_c = 0, 0\n",
    "    total_n, correct_n = 0, 0\n",
    "    total_o, correct_o = 0, 0\n",
    "\n",
    "    for i in range(3):\n",
    "        true[i] = true[i].to(device)\n",
    "        obj = true[i][..., 0] == 1\n",
    "        noobj = true[i][..., 0] == 0\n",
    "        correct_c += torch.sum(\n",
    "                torch.argmax(pred[i][..., 5][obj], dim=-1) == true[i][..., 5][obj]\n",
    "            )\n",
    "        total_c += torch.sum(obj)\n",
    "\n",
    "        obj_preds = torch.sigmoid(pred[i][..., 0]) > CONF_THRESHOLD\n",
    "        correct_o += torch.sum(obj_preds[obj] == true[i][..., 0][obj])\n",
    "        total_o += torch.sum(obj)\n",
    "        correct_n += torch.sum(obj_preds[noobj] == true[i][..., 0][noobj])\n",
    "        total_n += torch.sum(noobj)\n",
    "\n",
    "    acc_c = correct_c / total_c * 100\n",
    "    acc_o = correct_o / total_o * 100\n",
    "    acc_n = correct_n / total_n * 100\n",
    "\n",
    "    return acc_c.item(), acc_o.item(), acc_n.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model, train_loader, optimizer, loss, scaled_anchors, scaler, device='cuda'):\n",
    "    tq = tqdm(train_loader, leave=True, desc=\"Train\")\n",
    "    losses = []\n",
    "    accuracy = []\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for i, (data, target) in enumerate(tq):\n",
    "        data = data.to(device)\n",
    "        t0, t1, t2 = target[0].to(device), target[1].to(device), target[2].to(device)\n",
    "\n",
    "        with torch.cuda.amp.autocast():\n",
    "            out = model(data)\n",
    "\n",
    "            l = (loss(out[0], t0, scaled_anchors[0]) +\n",
    "                 loss(out[1], t1, scaled_anchors[1]) +\n",
    "                 loss(out[2], t2, scaled_anchors[2]))\n",
    "\n",
    "        losses.append(l.item())\n",
    "        optimizer.zero_grad()\n",
    "        scaler.scale(l).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        l.detach()\n",
    "\n",
    "        mean_loss = sum(losses) / len(losses)\n",
    "        tq.set_postfix(loss=mean_loss)\n",
    "\n",
    "        acc = get_accuracy(target, out, device)\n",
    "        accuracy.append(acc)\n",
    "\n",
    "    mean_loss = sum(losses) / len(losses)\n",
    "    avg_acc = np.array(accuracy).mean(axis=0)\n",
    "    return mean_loss, avg_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val(model, val_loader, optimizer, loss, scaled_anchors, scaler, device='cuda'):\n",
    "    tq = tqdm(val_loader, leave=True, desc=\"Val\")\n",
    "    losses = []\n",
    "    accuracy = []\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (data, target) in enumerate(tq):\n",
    "            data = data.to(device)\n",
    "            t0, t1, t2 = target[0].to(device), target[1].to(device), target[2].to(device)\n",
    "            out = model(data)\n",
    "\n",
    "            l = (loss(out[0], t0, scaled_anchors[0]) +\n",
    "                 loss(out[1], t1, scaled_anchors[1]) +\n",
    "                 loss(out[2], t2, scaled_anchors[2]))\n",
    "\n",
    "            losses.append(l.detach().item())\n",
    "\n",
    "            mean_loss = sum(losses) / len(losses)\n",
    "            tq.set_postfix(loss=mean_loss)\n",
    "\n",
    "            acc = get_accuracy(target, out, device)\n",
    "            accuracy.append(acc)\n",
    "\n",
    "    mean_loss = sum(losses) / len(losses)\n",
    "    avg_acc = np.array(accuracy).mean(axis=0)\n",
    "    return mean_loss, avg_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader, optimizer, loss, scaled_anchors, scaler, device='cuda'):\n",
    "    tq = tqdm(test_loader, leave=True, desc=\"Test\")\n",
    "    losses = []\n",
    "    accuracy = []\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (data, target) in enumerate(tq):\n",
    "            data = data.to(device)\n",
    "            t0, t1, t2 = target[0].to(device), target[1].to(device), target[2].to(device)\n",
    "            out = model(data)\n",
    "\n",
    "            l = (loss(out[0], t0, scaled_anchors[0]) +\n",
    "                 loss(out[1], t1, scaled_anchors[1]) +\n",
    "                 loss(out[2], t2, scaled_anchors[2]))\n",
    "\n",
    "            losses.append(l.detach().item())\n",
    "\n",
    "            mean_loss = sum(losses) / len(losses)\n",
    "            tq.set_postfix(loss=mean_loss)\n",
    "\n",
    "            acc = get_accuracy(target, out, device)\n",
    "            accuracy.append(acc)\n",
    "\n",
    "    mean_loss = sum(losses) / len(losses)\n",
    "    avg_acc = np.array(accuracy).mean(axis=0)\n",
    "    return mean_loss, avg_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, val_loader, test_loader, optimizer, \n",
    "          loss, anchors, S, start_epoch, epochs, best_loss, name=\"test_name\", device='cuda'):\n",
    "    scaled_anchors = (torch.tensor(anchors) * \n",
    "                     torch.tensor(S).unsqueeze(1).unsqueeze(1).repeat(1, 3, 2))\n",
    "    scaled_anchors = scaled_anchors.to(device)\n",
    "\n",
    "    best_model = model.state_dict()\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "    history = {}\n",
    "    history['train_loss'] = []\n",
    "    history['train_acc'] = []\n",
    "    history['val_loss'] = []\n",
    "    history['val_acc'] = []\n",
    "\n",
    "    history['test_loss'] = 0\n",
    "    history['test_acc'] = 0\n",
    "\n",
    "    for epoch in range(1 + start_epoch, 1+epochs):\n",
    "        train_loss, train_acc = train_step(model, train_loader, \n",
    "                                           optimizer, loss, scaled_anchors,\n",
    "                                           scaler, device)\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "\n",
    "        val_loss, val_acc = val(model, val_loader, \n",
    "                                optimizer, loss, \n",
    "                                scaled_anchors, scaler, device)\n",
    "\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_acc'].append(val_acc)\n",
    "\n",
    "        if best_loss == best_loss and (best_loss is None or val_loss < best_loss):\n",
    "            best_model = model.state_dict()\n",
    "            best_loss = val_loss\n",
    "\n",
    "            save_model(model, optimizer, epoch, best_loss, name)\n",
    "\n",
    "    test_loss, test_acc = test(model, test_loader, optimizer, loss, \n",
    "                               scaled_anchors, scaler, device)\n",
    "\n",
    "    history['test_loss'] = test_loss\n",
    "    history['test_acc'] = test_acc\n",
    "\n",
    "    model.load_state_dict(best_model)\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = nn.MSELoss()\n",
    "bce = nn.BCEWithLogitsLoss()\n",
    "entropy = nn.CrossEntropyLoss()\n",
    "\n",
    "def Loss(predictions, target, anchors):\n",
    "    obj = target[..., 0] == 1\n",
    "    noobj = target[..., 0] == 0 \n",
    "\n",
    "    no_object_loss = bce(\n",
    "        (predictions[..., 0:1][noobj]), (target[..., 0:1][noobj]),\n",
    "    )\n",
    "\n",
    "    anchors = anchors.reshape(1, 3, 1, 1, 2)\n",
    "    box_preds = torch.cat([torch.sigmoid(predictions[..., 1:3]), torch.exp(predictions[..., 3:5]) * anchors], dim=-1)\n",
    "    ious = intersection_over_union(box_preds[obj], target[..., 1:5][obj]).detach()\n",
    "    object_loss = mse(torch.sigmoid(predictions[..., 0:1][obj]), ious * target[..., 0:1][obj])\n",
    "\n",
    "    predictions[..., 1:3] = torch.sigmoid(predictions[..., 1:3])\n",
    "    target[..., 3:5] = torch.log(\n",
    "        (1e-16 + target[..., 3:5] / anchors)\n",
    "    )\n",
    "    box_loss = mse(predictions[..., 1:5][obj], target[..., 1:5][obj])\n",
    "\n",
    "\n",
    "    class_loss = entropy(\n",
    "        (predictions[..., 5:][obj]), (target[..., 5][obj].long()),\n",
    "    )\n",
    "\n",
    "    return (10 * box_loss + 1 * object_loss + 10 * no_object_loss + 1 * class_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**第六部分 模型训练过程**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_train = int(len(ANNOTATIONS) * 0.70)\n",
    "idx_test = int(len(ANNOTATIONS) * 0.85)\n",
    "# train_ann = ANNOTATIONS[:idx_train] train for a bit on entire dataset before export\n",
    "train_ann = ANNOTATIONS\n",
    "val_ann = ANNOTATIONS[idx_train:idx_test] # 验证集\n",
    "test_ann = ANNOTATIONS[idx_test:] # 测试集\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "LEARNING_RATE = 1e-5\n",
    "WEIGHT_DECAY = 1e-4\n",
    "NUM_EPOCHS = 20\n",
    "\n",
    "test_dataset = CustomDataset(test_ann, IMAGE_DIR, LABEL_DIR,\n",
    "                             ANCHORS, image_size=416,\n",
    "                             S=[13, 26, 52], C=20,\n",
    "                             transforms=test_transforms)\n",
    "test_loader = DataLoader(test_dataset, shuffle=True, batch_size=BATCH_SIZE)\n",
    "\n",
    "train_dataset = CustomDataset(train_ann, IMAGE_DIR, LABEL_DIR,\n",
    "                             ANCHORS, image_size=416,\n",
    "                             S=[13, 26, 52], C=20,\n",
    "                             transforms=train_transforms)\n",
    "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=BATCH_SIZE)\n",
    "\n",
    "val_dataset = CustomDataset(val_ann, IMAGE_DIR, LABEL_DIR,\n",
    "                             ANCHORS, image_size=416,\n",
    "                             S=[13, 26, 52], C=20,\n",
    "                             transforms=test_transforms)\n",
    "val_loader = DataLoader(val_dataset, shuffle=True, batch_size=BATCH_SIZE)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = YOLOv3(3, 20).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "start_epoch = 0\n",
    "best_loss = None\n",
    "load = True\n",
    "\n",
    "\n",
    "if load:\n",
    "    checkpoint = torch.load(\"trained_models/YOLOv3/model.pth\")\n",
    "    start_epoch =  checkpoint['epoch']\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    best_loss = checkpoint['loss']\n",
    "    print(start_epoch, best_loss)\n",
    "\n",
    "# 模型训练\n",
    "history = train(model, train_loader, val_loader, test_loader, optimizer, \n",
    "          Loss, ANCHORS, S, start_epoch, NUM_EPOCHS, best_loss, 'YOLOv3', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**第七部分 训练过程曲线可视化**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_loss(history):\n",
    "    ind = list(range(len(history['train_loss'])))\n",
    "    plt.plot(ind, history['train_loss'], label='line1')\n",
    "    plt.plot(ind, history['val_loss'], label='line2')\n",
    "    plt.scatter(ind[-1], history['test_loss'], label='point1')\n",
    "\n",
    "    plt.legend([\n",
    "        'train_loss',\n",
    "        'val_loss',\n",
    "        'test_loss'\n",
    "    ])\n",
    "\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Losses plot')\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def display_acc(history):\n",
    "    accs_train = np.stack(history['train_acc'], axis=0)\n",
    "    accs_test = np.stack(history['test_acc'], axis=0)\n",
    "    accs_val = np.stack(history['val_acc'], axis=0)\n",
    "\n",
    "    fig, ax = plt.subplots(3)\n",
    "    plt.subplots_adjust(top=1.2, hspace=0.4)\n",
    "\n",
    "    labels = ['Class accuracy', 'Object accuracy', 'No object accuracy']\n",
    "\n",
    "    for i in range(3):\n",
    "        a_tr = accs_train[:, i]\n",
    "        a_ts = accs_test[i]\n",
    "        a_vl = accs_val[:, i]\n",
    "        ind = list(range(len(a_tr)))\n",
    "        ax[i].plot(ind, a_tr, label='line1')\n",
    "        ax[i].plot(ind, a_vl, label='line2')\n",
    "        ax[i].scatter(ind[-1], a_ts, label='point1')\n",
    "\n",
    "        ax[i].legend([\n",
    "            'train_acc',\n",
    "            'val_acc',\n",
    "            'test_acc'\n",
    "        ])\n",
    "\n",
    "        ax[i].set_ylabel('Accuracy')\n",
    "        ax[i].set_title(labels[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可视化loss曲线\n",
    "display_loss(history)\n",
    "# 可视化accuracy曲线\n",
    "display_acc(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**第八部分 图像检测可视化**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(images, bboxes):\n",
    "    cmap = plt.get_cmap('tab20b')\n",
    "    colors = [cmap(i) for i in np.linspace(0, 1, len(CLASS_INDICES))]\n",
    "\n",
    "    n = int(np.sqrt(len(images)))\n",
    "    fig, ax = plt.subplots(n, n, figsize=(10, 10))\n",
    "    plt.subplots_adjust(top=0.95, hspace=0.4)\n",
    "    \n",
    "    for idx, (img, boxes) in enumerate(zip(images, bboxes)):\n",
    "        image = img.to('cpu').permute(1, 2, 0).numpy()\n",
    "        h, w, _ = image.shape\n",
    "        i = idx % n\n",
    "        j = idx // n\n",
    "\n",
    "        ax[i][j].imshow(image)\n",
    "\n",
    "        for box in boxes:\n",
    "            c = box[0]\n",
    "            box = box[2:]\n",
    "            up_l_x = box[0] - box[2] / 2\n",
    "            up_l_y = box[1] - box[3] / 2\n",
    "            rect = patches.Rectangle(\n",
    "                (up_l_x * w, up_l_y * h),\n",
    "                box[2] * w,\n",
    "                box[3] * h,\n",
    "                linewidth=2,\n",
    "                edgecolor=colors[int(c)],\n",
    "                facecolor='none'\n",
    "            )\n",
    "\n",
    "            ax[i][j].add_patch(rect)\n",
    "            ax[i][j].text(\n",
    "                up_l_x * w,\n",
    "                up_l_y * h,\n",
    "                s=CLASS_INDICES[int(c)],\n",
    "                color='white',\n",
    "                verticalalignment='top',\n",
    "                bbox={'color': colors[int(c)], 'pad': 0}\n",
    "            )\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "def cells_to_boxes(predict, predicted=True):\n",
    "    bboxes = []\n",
    "    anchors = ANCHORS\n",
    "    anchors = (torch.tensor(anchors) * \n",
    "                     torch.tensor(S).unsqueeze(1).unsqueeze(1).repeat(1, 3, 2))\n",
    "    for idx, pred in enumerate(predict):\n",
    "        bboxes.append(get_box(pred, pred.shape[2], anchors[idx], predicted))\n",
    "    new_boxes = torch.cat(\n",
    "        (torch.Tensor(bboxes[0]),\n",
    "        torch.Tensor(bboxes[1]),\n",
    "        torch.Tensor(bboxes[2])), dim=1).tolist()\n",
    "    bboxes = []\n",
    "    for box in new_boxes:\n",
    "        bboxes.append(preprocess_boxes(box))\n",
    "    return bboxes\n",
    "\n",
    "def preprocess_boxes(bboxes, iou_thresh=NMS_IOU_THRESH, thresh=0.7):\n",
    "    new_boxes = []\n",
    "    bboxes = [box for box in bboxes if box[1] > thresh]\n",
    "    bboxes = sorted(bboxes, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    while bboxes:\n",
    "        chosen = bboxes.pop(0)\n",
    "        bboxes = [\n",
    "            box \n",
    "            for box in bboxes\n",
    "            if int(box[0]) != int(chosen[0])\n",
    "            or intersection_over_union(\n",
    "                torch.tensor(chosen[2:]), torch.tensor(box[2:])) < iou_thresh\n",
    "        ]\n",
    "        new_boxes.append(chosen)\n",
    "    return new_boxes\n",
    "\n",
    "\n",
    "def get_box(box, scale, anchors, pred=True):\n",
    "    num_a = len(anchors)\n",
    "    preds = box[..., 1:5]\n",
    "    batch_size = box.shape[0]\n",
    "    if pred:\n",
    "        anchors = torch.Tensor(anchors).reshape(1, len(anchors), 1, 1, 2)\n",
    "        preds[..., 0:2] = torch.sigmoid(preds[..., 0:2])\n",
    "        preds[..., 2:] = torch.exp(preds[..., 2:]) * anchors\n",
    "        scores = torch.sigmoid(box[..., 0:1])\n",
    "        best_class = torch.argmax(box[..., 5:], dim=-1).unsqueeze(-1)\n",
    "    else:\n",
    "        scores = box[..., 0:1]\n",
    "        best_class = box[..., 5:6]\n",
    "\n",
    "    cell_indices = torch.arange(scale).repeat(box.shape[0], 3, scale, 1).unsqueeze(-1)\n",
    "    x = 1.0 / scale * (preds[..., 0:1] + cell_indices)\n",
    "    y = 1.0 / scale * (preds[..., 1:2] + cell_indices.permute(0, 1, 3, 2, 4))\n",
    "    w_h = 1.0 / scale * preds[..., 2:4]\n",
    "    new_boxes = torch.cat((best_class, scores, x, y, w_h), dim=-1).reshape(batch_size, num_a * scale * scale, 6)\n",
    "    return new_boxes.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用训练好的模型检测4张VOC数据集里的图像\n",
    "\n",
    "test_dataset = CustomDataset(ANNOTATIONS[:4], IMAGE_DIR, LABEL_DIR,\n",
    "                             ANCHORS, image_size=416,\n",
    "                             S=[13, 26, 52], C=20,\n",
    "                             transforms=test_transforms)\n",
    "\n",
    "test_loader = DataLoader(test_dataset, shuffle=True, batch_size=4)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = YOLOv3(3, 20).to(device)\n",
    "\n",
    "for data, target in test_loader:\n",
    "    out = model(data.to(device))\n",
    "    for i in range(len(out)):\n",
    "        out[i] = out[i].to('cpu')\n",
    "    data.to('cpu')\n",
    "    bbox = cells_to_boxes(out, True)\n",
    "    plot_image(data, bbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入模型检测测试集种的16张图像\n",
    "\n",
    "test_dataset = CustomDataset(test_ann, IMAGE_DIR, LABEL_DIR,\n",
    "                             ANCHORS, image_size=416,\n",
    "                             S=[13, 26, 52], C=20,\n",
    "                             transforms=test_transforms)\n",
    "test_loader = DataLoader(test_dataset, shuffle=True, batch_size=BATCH_SIZE)\n",
    "\n",
    "model = YOLOv3(3, 20).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "load = True\n",
    "if load: # 导入训练好的模型\n",
    "    checkpoint = torch.load(\"trained_models/YOLOv3/best_model.pth\") # ,map_location='cpu'\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "\n",
    "for data, target in test_loader:\n",
    "    out = model(data.to(device))\n",
    "    for i in range(len(out)):\n",
    "        out[i] = out[i].to('cpu')\n",
    "    data.to('cpu')\n",
    "    bbox = cells_to_boxes(out, True)\n",
    "    plot_image(data, bbox)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试自己放入的三张图片（事先按照VOC数据集的格式将图片放入数据集），由于batch_size设置为16，因此只能将三张自定义图片混入测试\n",
    "IMAGE_DIR = 'test_data/JPEGImages'\n",
    "ANNOTATIONS_DIR = 'test_data/Annotations'\n",
    "LABEL_DIR = 'test_data/Labels'\n",
    "ANNOTATIONS = ['2007_000063',\n",
    " '2007_000068',\n",
    " '2007_000027',\n",
    " '2007_000032',\n",
    " '2007_000033',\n",
    " '2007_000061',\n",
    " '2007_000175',\n",
    " '2007_000170',\n",
    " '2007_000123',\n",
    " '2007_000121',\n",
    " '2007_000039',\n",
    " '2007_000042',\n",
    " '2007_000129',\n",
    " '2007_000187',\n",
    " '2007_000241',\n",
    " '2007_000243']\n",
    "\n",
    "\n",
    "test_dataset = CustomDataset(ANNOTATIONS, IMAGE_DIR, LABEL_DIR,\n",
    "                             ANCHORS, image_size=416,\n",
    "                             S=[13, 26, 52], C=20,\n",
    "                             transforms=test_transforms)\n",
    "test_loader = DataLoader(test_dataset, shuffle=True, batch_size=BATCH_SIZE)\n",
    "\n",
    "model = YOLOv3(3, 20).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "load = True\n",
    "if load:\n",
    "    checkpoint = torch.load(\"trained_models/YOLOv3/best_model.pth\") # ,map_location='cpu'\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "for data, target in test_loader:\n",
    "    out = model(data.to(device))\n",
    "    for i in range(len(out)):\n",
    "        out[i] = out[i].to('cpu')\n",
    "    data.to('cpu')\n",
    "    bbox = cells_to_boxes(out, True)\n",
    "    plot_image(data, bbox)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看显存是否够用\n",
    "!nvidia-smi"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1b3e7639de1c5d6c142dc4b5962db69f2197035c5298bc6cbd8b8fcb10fc3cd2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
